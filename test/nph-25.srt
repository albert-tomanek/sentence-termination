1
00:00:00,000 --> 00:00:04,600
Compression is reducing the amount of information

2
00:00:04,600 --> 00:00:07,760
but without, in a sense, losing any of it.

3
00:00:07,760 --> 00:00:13,640
Trying to compress it and shorten it in such a way that you could in principle recover

4
00:00:13,640 --> 00:00:16,260
the full information that you started with,

5
00:00:16,260 --> 00:00:20,380
but in terms of transmitting it over a network, it's going to cost you less

6
00:00:20,380 --> 00:00:23,120
because you pay per bit or per byte or whatever.

7
00:00:23,120 --> 00:00:27,000
And if you could get the number of bytes down that you need to transmit

8
00:00:27,000 --> 00:00:31,960
to get something across the wire, then that benefits everybody, generally.

9
00:00:33,480 --> 00:00:38,240
You do sometimes not compress because the following

10
00:00:38,240 --> 00:00:46,040
drawback happens. If you compress something then you have to decompress it to get back the full story,

11
00:00:46,040 --> 00:00:50,040
that decompression takes time at the other end.

12
00:00:50,040 --> 00:00:54,200
You have to get a computer on it saying: "this was transmitted compressed,

13
00:00:54,200 --> 00:00:57,040
because it saved BT bandwidth cost,

14
00:00:57,040 --> 00:01:01,720
but now I'm at this end and I want to see the real picture, I've got to uncompress it."

15
00:01:01,720 --> 00:01:06,860
So, the nice thing about not compressing, if you don't mind the amount of data,

16
00:01:06,860 --> 00:01:09,860
is it's there at the other end and it's instantly processable.

17
00:01:09,860 --> 00:01:16,900
You compress data essentially by looking for repeated patterns and predictability.

18
00:01:16,900 --> 00:01:21,860
And I think, if you take an example, shall we say of a text file,

19
00:01:21,860 --> 00:01:24,940
something that repeats itself over and over again

20
00:01:24,940 --> 00:01:30,620
with the stock buzzphrases used over and over and over again is going to be pretty compressable.

21
00:01:30,620 --> 00:01:33,100
If somebody writes a report that's got the phrase

22
00:01:33,100 --> 00:01:37,360
"meaningful and relevant scenarios at this point in time going forward",

23
00:01:37,360 --> 00:01:42,060
then you take that out and it's being used a thousand times and it drives you mad

24
00:01:42,060 --> 00:01:45,040
and you make one copy of it at the top of the file,

25
00:01:45,040 --> 00:01:49,360
and that's maybe, I don't know, 50 characters, 50 bites, and you say

26
00:01:49,360 --> 00:01:54,560
"I'm NOT gonna spend 50 bites repeating that phrase everytime in this report,

27
00:01:54,560 --> 00:01:59,900
I'm gonna compress it." You take one copy and take a note of where it occurs in the file.

28
00:01:59,900 --> 00:02:06,280
It occurs at <start position> 20, 800,1500 and so on.

29
00:02:06,280 --> 00:02:11,640
And you can save a huge amount because those numbers take three or four bytes each

30
00:02:11,640 --> 00:02:13,680
not a hundred bytes every time.

31
00:02:13,680 --> 00:02:19,540
Pictures are harder, coming back to this idea of what makes things compressible

32
00:02:19,540 --> 00:02:21,580
is predictability.

33
00:02:21,580 --> 00:02:24,760
Then, if you think about a photograph

34
00:02:24,760 --> 00:02:28,380
some photographs, you could say, do have predictable areas.

35
00:02:28,380 --> 00:02:32,980
You could take, shall we say, a photograph of,

36
00:02:32,980 --> 00:02:35,160
like on Microsoft Windows,

37
00:02:35,160 --> 00:02:39,180
there's a yellow desert island in the middle of the Pacific Ocean

38
00:02:39,180 --> 00:02:41,120
with one green tree.

39
00:02:41,120 --> 00:02:45,060
Now that's easy, because the Pacific is totally smooth,

40
00:02:45,060 --> 00:02:47,060
you've got thousands of blue pixels,

41
00:02:47,060 --> 00:02:50,340
you've got hundreds of yellow pixels for the desert island,

42
00:02:50,340 --> 00:02:52,260
a few hundred more for the tree.

43
00:02:52,260 --> 00:02:57,540
So you can compress it, not by sending every single pixel individually,

44
00:02:57,540 --> 00:02:59,420
but by saying: "There's the sea,

45
00:02:59,420 --> 00:03:03,560
there's the color blue, there's a thousand of those, just replicate them,

46
00:03:03,560 --> 00:03:06,660
similarly for the desert island and the tree.

47
00:03:06,660 --> 00:03:12,720
So, that's what I mean about the element of predictability or common areas inside a picture.

48
00:03:12,720 --> 00:03:15,260
Now, the average photo you take

49
00:03:15,260 --> 00:03:19,760
maybe fairly simple if it's an indoor photo with flat surfaces

50
00:03:19,760 --> 00:03:23,840
but you imagine taking a photograph, for example,

51
00:03:23,840 --> 00:03:32,500
of a sports car race, or of an impressionist picture with blobs of painting all over,

52
00:03:32,500 --> 00:03:34,220
all over the place, you know,

53
00:03:34,220 --> 00:03:40,200
that's much more random and there isn't a pattern that you can pick up on to make it easily compressible.

54
00:03:40,200 --> 00:03:44,360
You best have to take a deep breath and say: "I'm gonna have to transmit the whole thing

55
00:03:44,360 --> 00:03:46,200
because I can't see any patterns in here."

56
00:03:46,200 --> 00:03:50,020
You were talking about these blue pixels, there may be a thousand blue pixels,

57
00:03:50,020 --> 00:03:54,780
but the computer still has to know where to put every single one, so how are we saving time?

58
00:03:54,780 --> 00:03:57,860
You still have to transmit some minimal information

59
00:03:57,860 --> 00:04:00,880
as to where to start laying these pixels out on the screen.

60
00:04:00,880 --> 00:04:07,440
You say: "start at such and such a position, and the XY, you know how wide the picture is,

61
00:04:07,440 --> 00:04:11,920
just spew out ten thousand blue pixels and see how it fits in."

62
00:04:11,920 --> 00:04:19,300
What you don't have to say is "here is the spec of the blue pixel for position 1000, here is the same spec

63
00:04:19,300 --> 00:04:23,680
for the blue pixel at position 1001", you don't need to do that.

64
00:04:23,680 --> 00:04:28,660
You just send the spec once and say "replicate it for hundred, or whatever times".

65
00:04:28,660 --> 00:04:30,660
Well, I'm making it simpler than it is.

66
00:04:30,660 --> 00:04:34,480
Perhaps one good example would be the JPEG compression.

67
00:04:34,480 --> 00:04:40,160
It's very common, has to be done to be able to get photographs down for size

68
00:04:40,160 --> 00:04:44,400
to uploading to sites like Picasa and Flickr, they're not going to be happy

69
00:04:44,400 --> 00:04:49,840
having every single one of your photos taking up 20 MB and being utterly perfect.

70
00:04:49,840 --> 00:04:52,320
They want to compress it down to kilobytes.

71
00:04:52,320 --> 00:05:00,360
And the problem is that many, particularly scenery and so on, is inately random enough looking

72
00:05:00,360 --> 00:05:02,060
that it's not easy to compress.

73
00:05:02,060 --> 00:05:09,260
So JPEG is an example of a compression that goes by the name of 'lossy'.

74
00:05:09,600 --> 00:05:13,620
When we discussed earlier about compression, in the text case,

75
00:05:13,620 --> 00:05:18,280
I put it to you that you could always recover the exact file

76
00:05:18,280 --> 00:05:22,300
because you had your buzzphrase, all the places it was replicated,

77
00:05:22,300 --> 00:05:27,900
nothing to stop you at the far end undoing all that and building it back exactly as it was with no loss.

78
00:05:28,360 --> 00:05:33,500
In a photographic case, you could try and do that, but you wouldn't get much compression,

79
00:05:33,500 --> 00:05:35,720
because there's no predictability.

80
00:05:35,720 --> 00:05:42,220
So what JPEG does, is it basically says: "if you allow me to do some really clever things,

81
00:05:42,220 --> 00:05:45,920
I will try and get more compression out of it

82
00:05:45,920 --> 00:05:52,800
but I may make the edges of your picture look a bit blurry and fuzzy as you magnify them."

83
00:05:52,800 --> 00:05:56,220
And it's doing it by all sorts of tricks, about

84
00:05:56,220 --> 00:06:03,160
dividing the picture up in two, blocks and squares, and saying "well, this is almost the same green,

85
00:06:03,160 --> 00:06:05,620
I'll use this as an approximation."

86
00:06:05,620 --> 00:06:10,820
It's never recoverable exactly the way you started

87
00:06:10,840 --> 00:06:15,380
but you get a lot more compression that way, if you don't mind an approximation.

88
00:06:15,380 --> 00:06:21,360
And for people in the human visual system looking at something that can often be pretty good.

89
00:06:21,360 --> 00:06:22,640
Particularly on a screen.

90
00:06:22,720 --> 00:06:28,780
What are the compressing geniuses in their compression HQ trying to do at the moment

91
00:06:28,780 --> 00:06:32,620
or is it kind of, have they reached their limit? Surely, this has a limit?

92
00:06:32,620 --> 00:06:38,200
There is a limit, this is something that's covered by fascinating topical information theory.

93
00:06:38,200 --> 00:06:41,040
Information theory will tell you

94
00:06:41,040 --> 00:06:43,400
what is called the entropy limit.

95
00:06:43,400 --> 00:06:48,540
Now, many viewers of this video will have heard of entropy, and will freeze solid,

96
00:06:48,540 --> 00:06:51,740
because they were taught it in physics and chemistry, right?

97
00:06:51,740 --> 00:06:57,680
As a computer scientist, and an ex-chemist, let me tell you learning about entropy is a lot easier

98
00:06:57,680 --> 00:06:59,580
from a computer science standpoint.

99
00:06:59,580 --> 00:07:01,280
No question about it.

100
00:07:01,280 --> 00:07:03,780
You can work out, for example,

101
00:07:03,780 --> 00:07:12,100
what's the minimum number of bits I need to transmit a piece of information in a lossless way.

102
00:07:12,100 --> 00:07:13,560
Let's concentrate on that.

103
00:07:13,560 --> 00:07:18,320
What's the minimum number of bits I can get away with, and, I could,...

104
00:07:18,320 --> 00:07:19,800
Let's get you a piece of paper.

